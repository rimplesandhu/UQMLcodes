Sparse leanring algorithms are aimed at identifying a sparse structure of basis in a flexible model using system observations. These codes were writen while I was trying to understand the existing sparse learning algorithms. The idea was to investigate the underpinings of sparse learning algorithms by writing my own codes for a simple case of polynomial regression with scalar input and scalar output. Although I wrote the code for polynomial basis with scalar input, it could be easily extended to multiple inputs and other basis functions with a slight modification. The codes are written in a way that they are simple to read and easy to modify. Please email rimple_sandhu at outlook.com for any suggestions/corrections. The codes are present in the jupyter notebook format (*.ipynb) and as a python executable script (*.py). 

Please see 'sparse_learning_regression.pdf' available in the repo for theory and discussion of the results obtained using these codes. Here is a brief description of each code: 


:: 0_generate.py
Generates the noisy observations using polynomial basis, to be used for the application of frequentist and Bayesian sparse learning algorithms. 

:: 1_RLS.py
Cmoputes the ordinary least-square (OLS), LASSO and Ridge regression solution using the noisy observations generated by '0_generate.py'. The OLS and Ridge regression are computed analytically while LASSO solution is obtained through numerical optimization of LASSO cost function. The cross-validation prediction error is also plotted for LASSO and Ridge regression, which can be used to obtain an optimla value of regularization coefficient lambda.
Ref: Hastie, Trevor, Tibshirani, Robert and Friedman, Jerome. The Elements of Statistical Learning. New York, NY, USA: Springer New York Inc., 2001.

:: 2_BLRrhoknown.py
Bayesian linear regression code assuming observation error precision (rho) is known. Uses conjugate prior (Normal) for parameter vector w to compute posterior pdf and log-evidence analytically.

:: 3_BLR.py
Bayesian linear regression code where both w and rho are unknown. Uses Normal-Gamma conjugate prior NG(m0,V0,a0,b0) to obtain posterior pdf of model parameter w and error precision rho, and log-evidence analytically.
Ref: Hastie, Trevor, Tibshirani, Robert and Friedman, Jerome. The Elements of Statistical Learning. New York, NY, USA: Springer New York Inc., 2001.

:: 4_SBLorig.py
Sparse Bayesian learning code that involves iterative re-estimation procedure for hyper-parameter estimation.   
Ref: Michael E. Tipping.  Sparse bayesian learning and the relevance vector machine. 2001.

:: 5_SBLfast.py
Sparse Bayesian leanring code that involves fast suboptimal iterative addition/deletion procedure for basis selection.
Ref: Michael E. Tipping and Anita C. Faul.  Fast marginal likelihood maximisation for sparse bayesian models. 2003.

:: 6_BCS.py
Bayesian compressive sensing code that uses two-level hierarchical prior for inducing sparsity. 
Ref: S. D. Babacan, R. Molina and A. K. Katsaggelos, "Bayesian Compressive Sensing Using Laplace Priors," in IEEE Transactions on Image Processing, vol. 19, no. 1, pp. 53-63, Jan. 2010.



